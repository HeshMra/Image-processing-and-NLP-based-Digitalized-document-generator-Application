{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests,io\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from fpdf import FPDF\n",
    "from gtts import gTTS\n",
    "import easyocr, torch, os\n",
    "import language_tool_python\n",
    "from google.cloud import vision\n",
    "from matplotlib import pyplot as plt\n",
    "from google.cloud.vision_v1.types import Image\n",
    "from google.oauth2.service_account import Credentials\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_handwritten_text(path):\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    page = response.full_text_annotation.pages[0]\n",
    "    parapgraph_texts = ''\n",
    "    for block in page.blocks:\n",
    "        parapgraph_text = ''\n",
    "        for paragraph in block.paragraphs:\n",
    "            for word in paragraph.words:\n",
    "                word_text = ''.join([\n",
    "                    symbol.text for symbol in word.symbols\n",
    "                ])\n",
    "                parapgraph_text += word_text + ' '\n",
    "        parapgraph_texts += parapgraph_text + ' '\n",
    "    return parapgraph_texts\n",
    "\n",
    "def detect_gantt_chart(path):\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image(content=content)\n",
    "    response = client.document_text_detection(image=image)\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    page = response.full_text_annotation.pages[0]\n",
    "    parapgraph_texts = []\n",
    "    for block in page.blocks:\n",
    "        parapgraph_text = ''\n",
    "        for paragraph in block.paragraphs:\n",
    "            for word in paragraph.words:\n",
    "                word_text = ''.join([\n",
    "                    symbol.text for symbol in word.symbols\n",
    "                ])\n",
    "                parapgraph_text += word_text + ' '\n",
    "        parapgraph_texts.append(parapgraph_text)\n",
    "\n",
    "    deadlines = parapgraph_texts[-4:]\n",
    "    tasks = parapgraph_texts[1:-5]\n",
    "\n",
    "    task_dict = {}\n",
    "    for i in range(len(tasks)):\n",
    "        task_dict[tasks[i].strip()] = deadlines[i].strip()\n",
    "    return task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_text_classification(corrected_text):\n",
    "    try:\n",
    "        tokenized_products = tokenizer.encode_plus(\n",
    "                                                    corrected_text, \n",
    "                                                    return_tensors='pt', \n",
    "                                                    max_length=len(corrected_text.split()), \n",
    "                                                    pad_to_max_length=True\n",
    "                                                    )\n",
    "        preditions = nli_model(**tokenized_products)\n",
    "        logits = preditions.logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        probs = probs.detach().numpy()\n",
    "        probs = np.array(probs, dtype=np.object)\n",
    "        probs = probs[:, 1]\n",
    "        output = candidates[np.argmax(probs)]\n",
    "    except:\n",
    "        predition = classifier(corrected_text, candidates, multi_label=True)\n",
    "        output = predition['labels'][np.argmax(predition['scores'])]\n",
    "    return output\n",
    "\n",
    "def write_to_pdf(text, task_type, pdf=None):\n",
    "    pdf_args = pdf\n",
    "    if pdf is None:\n",
    "        pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "\n",
    "    if pdf_args is None:\n",
    "        pdf.set_font(\"Arial\", size = 25)\n",
    "        pdf.cell(\n",
    "                200, 10, \n",
    "                txt = ' '.join(task_type.split('_')),\n",
    "                ln = 1, \n",
    "                align = 'C'\n",
    "                )\n",
    "    \n",
    "    text = text.split()\n",
    "    pdf.set_font(\"Arial\", size = 12)\n",
    "\n",
    "    max_characters_per_line = 100\n",
    "    curr_line = ''\n",
    "    for i in range(len(text)):\n",
    "        if len(curr_line) + len(text[i]) > max_characters_per_line:\n",
    "            pdf.cell(200, 10, txt = curr_line, ln = 1, align = 'L')\n",
    "            curr_line = text[i] + ' '\n",
    "        else:\n",
    "            curr_line += text[i] + ' '\n",
    "\n",
    "\n",
    "    return pdf\n",
    "\n",
    "def extract_single_image_content(image_path):\n",
    "    text = detect_handwritten_text(image_path)\n",
    "    task_type = zero_shot_text_classification(text)\n",
    "    write_to_pdf(text, task_type)\n",
    "    return text, task_type\n",
    "\n",
    "def component_01_pipeline(\n",
    "                        hand_written_image_paths,\n",
    "                        gantt_chart_image_path,\n",
    "                        digidoc_path = \"store/ocr/digidoc.pdf\",\n",
    "                        read_out_loud_path = \"store/ocr/read_out_loud.mp3\"\n",
    "                        ):\n",
    "    texts = []\n",
    "    task_types = []\n",
    "\n",
    "    for image_path in hand_written_image_paths:\n",
    "        text, task_type = extract_single_image_content(image_path)\n",
    "        texts.append(text)\n",
    "        task_types.append(task_type)\n",
    "\n",
    "    mode_task_type = max(set(task_types), key=task_types.count)\n",
    "    for idx, text in enumerate(texts):\n",
    "        if idx == 0:\n",
    "            pdf = write_to_pdf(text, mode_task_type)\n",
    "        else:\n",
    "            pdf = write_to_pdf(text, mode_task_type, pdf=pdf)\n",
    "        \n",
    "    pdf.output(digidoc_path)\n",
    "\n",
    "    gantt_chart_dict = detect_gantt_chart(gantt_chart_image_path)\n",
    "    deadline = gantt_chart_dict[mode_task_type]\n",
    "\n",
    "    today = datetime.date.today()\n",
    "    deadline = datetime.datetime.strptime(deadline, '%d/%m/%Y').date()\n",
    "    daysleft = deadline - today\n",
    "\n",
    "    readable_text = 'The Task Type for provided handwritten images is ' + ' '.join(mode_task_type.split('_')) + '.\\n'\n",
    "    for idx, text in enumerate(texts):\n",
    "        readable_text += 'Reading Page ' + str(idx + 1) + ':\\n'\n",
    "        readable_text += text + '\\n\\n'\n",
    "\n",
    "    readable_text += 'The deadline for the task is ' + deadline.strftime('%d/%m/%Y') + '.\\n'\n",
    "    readable_text += 'You have ' + str(daysleft.days) + ' days left to complete the task.\\n'\n",
    "    read_obj = gTTS(\n",
    "                    text=readable_text, \n",
    "                    lang='en', \n",
    "                    slow=False\n",
    "                    )\n",
    "    read_obj.save(read_out_loud_path)\n",
    "\n",
    "    return deadline.strftime('%d/%m/%Y'), daysleft.days, digidoc_path, read_out_loud_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9916\\3461370163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             ]\n\u001b[0;32m      6\u001b[0m \u001b[0mgantt_chart_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/ocr/Gantt.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcomponent_01_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhand_written_image_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgantt_chart_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9916\\612061523.py\u001b[0m in \u001b[0;36mcomponent_01_pipeline\u001b[1;34m(hand_written_image_paths, gantt_chart_image_path, digidoc_path, read_out_loud_path)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhand_written_image_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_single_image_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mtask_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9916\\612061523.py\u001b[0m in \u001b[0;36mextract_single_image_content\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_single_image_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_handwritten_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mtask_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzero_shot_text_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mwrite_to_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9916\\3413796590.py\u001b[0m in \u001b[0;36mdetect_handwritten_text\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_handwritten_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "hand_written_image_paths = [\n",
    "                            'data/ocr/HandWrittenData/1.jpg',\n",
    "                            'data/ocr/HandWrittenData/2.jpg',\n",
    "                            'data/ocr/HandWrittenData/3.jpg'\n",
    "                            ]\n",
    "gantt_chart_image_path = 'data/ocr/Gantt.jpg'\n",
    "component_01_pipeline(hand_written_image_paths, gantt_chart_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import torch, whisper, glob\n",
    "import torch.nn.functional as F\n",
    "from whisper.model import Whisper\n",
    "from typing import List, Optional, Dict\n",
    "from scrape import get_entire_web_google_results\n",
    "from whisper.tokenizer import Tokenizer, get_tokenizer\n",
    "from whisper.audio import N_FRAMES, N_MELS, log_mel_spectrogram, pad_or_trim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper Speech 2 Text Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_audio_features(audio_path: Optional[str], model: Whisper) -> torch.Tensor:\n",
    "    if audio_path is None:\n",
    "        segment = torch.zeros((N_MELS, N_FRAMES), dtype=torch.float32).to(model.device)\n",
    "    else:\n",
    "        mel = log_mel_spectrogram(audio_path)\n",
    "        segment = pad_or_trim(mel, N_FRAMES).to(model.device)\n",
    "    return model.embed_audio(segment.unsqueeze(0))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_average_logprobs(\n",
    "                                model: Whisper,\n",
    "                                audio_features: torch.Tensor,\n",
    "                                class_names: List[str],\n",
    "                                tokenizer: Tokenizer,\n",
    "                            ) -> torch.Tensor:\n",
    "    initial_tokens = (\n",
    "        torch.tensor(tokenizer.sot_sequence_including_notimestamps).unsqueeze(0).to(model.device)\n",
    "    )\n",
    "    eot_token = torch.tensor([tokenizer.eot]).unsqueeze(0).to(model.device)\n",
    "\n",
    "    average_logprobs = torch.zeros(len(class_names))\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_name_tokens = (\n",
    "            torch.tensor(tokenizer.encode(\" \" + class_name)).unsqueeze(0).to(model.device)\n",
    "        )\n",
    "        input_tokens = torch.cat([initial_tokens, class_name_tokens, eot_token], dim=1)\n",
    "\n",
    "        logits = model.logits(input_tokens, audio_features)  # (1, T, V)\n",
    "        logprobs = F.log_softmax(logits, dim=-1).squeeze(0)  # (T, V)\n",
    "        logprobs = logprobs[len(tokenizer.sot_sequence_including_notimestamps) - 1 : -1]  # (T', V)\n",
    "        logprobs = torch.gather(logprobs, dim=-1, index=class_name_tokens.view(-1, 1))  # (T', 1)\n",
    "        average_logprob = logprobs.mean().item()\n",
    "        average_logprobs[i] = average_logprob\n",
    "\n",
    "    return average_logprobs\n",
    "\n",
    "\n",
    "def calculate_internal_lm_average_logprobs(\n",
    "                                            model: Whisper,\n",
    "                                            class_names: List[str],\n",
    "                                            tokenizer: Tokenizer,\n",
    "                                            verbose: bool = False,\n",
    "                                        ) -> torch.Tensor:\n",
    "    audio_features_from_empty_input = calculate_audio_features(None, model)\n",
    "    average_logprobs = calculate_average_logprobs(\n",
    "                                                model=model,\n",
    "                                                audio_features=audio_features_from_empty_input,\n",
    "                                                class_names=class_names,\n",
    "                                                tokenizer=tokenizer,\n",
    "                                                )\n",
    "    if verbose:\n",
    "        print(\"Internal LM average log probabilities for each class:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"  {class_name}: {average_logprobs[i]:.3f}\")\n",
    "    return average_logprobs\n",
    "\n",
    "model_cache = {}\n",
    "\n",
    "def generate_candidate_str(command_path = 'data/voice_command/commands.txt'):\n",
    "    with open(command_path, 'r') as f:\n",
    "        commands = f.readlines()\n",
    "    commands = [c.strip() for c in commands]\n",
    "    commands = [c for c in commands if len(c) > 0]\n",
    "    commands = [f\"[{c}]\" for c in commands]\n",
    "    return ','.join(commands)\n",
    "\n",
    "def zero_shot_classify(\n",
    "                        audio_path: str, \n",
    "                        model_name = 'small'\n",
    "                        ) -> Dict[str, float]:\n",
    "    class_names = generate_candidate_str()\n",
    "    class_names = class_names.split(\",\")\n",
    "    tokenizer = get_tokenizer(multilingual=\".en\" not in model_name)\n",
    "\n",
    "    if model_name not in model_cache:\n",
    "        model = whisper.load_model(model_name)\n",
    "        model_cache[model_name] = model\n",
    "    else:\n",
    "        model = model_cache[model_name]\n",
    "\n",
    "    internal_lm_average_logprobs = calculate_internal_lm_average_logprobs(\n",
    "        model=model,\n",
    "        class_names=class_names,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    audio_features = calculate_audio_features(audio_path, model)\n",
    "    average_logprobs = calculate_average_logprobs(\n",
    "        model=model,\n",
    "        audio_features=audio_features,\n",
    "        class_names=class_names,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    average_logprobs -= internal_lm_average_logprobs\n",
    "    scores = average_logprobs.softmax(-1).tolist()\n",
    "    return {class_name: score for class_name, score in zip(class_names, scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze for all audio files in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_command(file_name):\n",
    "    return file_name.split('/')[-1]\n",
    "\n",
    "def process_output(output):\n",
    "    command = max(output, key=output.get)\n",
    "    command = command[1:-1]\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = glob.glob('data/voice_command/*/*.wav')\n",
    "audio_files = [audio_file.replace('\\\\', '/') for audio_file in audio_files]\n",
    "\n",
    "result_dict = {}\n",
    "result_dict['file_name'] = []\n",
    "result_dict['command'] = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    result = zero_shot_classify(audio_file)\n",
    "    result = process_output(result)\n",
    "    result_dict['file_name'].append(extract_command(audio_file))\n",
    "    result_dict['command'].append(result)\n",
    "    \n",
    "df = pd.DataFrame(result_dict)\n",
    "df.to_csv('data/voice_command/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_voice_command(audio_file):\n",
    "    result = zero_shot_classify(audio_file)\n",
    "    result = process_output(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_references(search_item):\n",
    "    df = get_entire_web_google_results(search_item)\n",
    "    df = df[['title', 'description', 'DOI']]\n",
    "    return df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'DOI': 'https://en.wikipedia.org/wiki/Economics',\n",
      "  'description': 'Economics is a social science that studies the production, '\n",
      "                 'distribution, and consumption of goods and services. ... '\n",
      "                 'Economics focuses on the behaviour and interactions of '\n",
      "                 'economic agents\\xa0...',\n",
      "  'title': 'Economics - Wikipedia'},\n",
      " {'DOI': 'https://www.investopedia.com/terms/e/economics.asp',\n",
      "  'description': 'Economics is a social science that focuses on the '\n",
      "                 'production, distribution, and consumption of goods and '\n",
      "                 'services, and analyzes the choices that individuals\\xa0...',\n",
      "  'title': 'Economics Defined with Types, Indicators, and Systems'},\n",
      " {'DOI': 'https://www.bu.edu/eci/files/2019/05/MIC_4e_Ch7.pdf',\n",
      "  'description': 'behavioral economics: a subfield of microeconomics that uses '\n",
      "                 'insights from various social and biological sciences to '\n",
      "                 'explore how people make actual economic\\xa0...',\n",
      "  'title': 'CHAPTER 7: ECONOMIC BEHAVIOR AND RATIONALITY'},\n",
      " {'DOI': 'https://www.investopedia.com/ask/answers/032515/how-does-economics-study-human-action-and-behavior.asp',\n",
      "  'description': 'Find out why economics can be considered a deductive social '\n",
      "                 'science, like sociology, and how human action and behavior '\n",
      "                 'informs economic calculation.',\n",
      "  'title': 'How does economics study human action and behavior?'},\n",
      " {'DOI': 'http://www2.ef.jcu.cz/~sulista/pages/kdfp/ENAS2-6.pdf',\n",
      "  'description': 'Economics is the social science that analyzes the '\n",
      "                 'production, distribution, and consumption of goods and '\n",
      "                 'services. Current economic models emerged from the\\xa0...',\n",
      "  'title': 'THE SCIENCE OF ECONOMICS Economics is the social science ...'}]\n"
     ]
    }
   ],
   "source": [
    "text = '''Economics is a social science that studies how societies allocate scarce resources among competing demands. It examines the production, distribution, and consumption of goods and services, as well as the behavior of individuals, firms, and governments in making economic decisions. “Economics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyzes what's viewed as basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers.”  The two main branches of economics are microeconomics, which focuses on individual economic behavior and decision-making, and macroeconomics, which looks at the economy as a whole. '''\n",
    "response = scraping_references(text)\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
